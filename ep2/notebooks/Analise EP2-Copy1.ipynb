{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "# s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "# s0 = df_to_work['review_text'][1009]\n",
    "# tknzr.tokenize(s0.lower())\n",
    "# s0.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as variáveis do projeto\n",
    "vocab_size = 200000  # Considerar 200k palavras\n",
    "maxlen = 200  # Considerar apenas as 100 primeiras palavras do texto da review\n",
    "\n",
    "embed_dim = 50 # tamanho do Embedding de cada token ( também do word2vec da NILC)\n",
    "num_heads = 2  # N. de cabeças de atenção\n",
    "ff_dim = 32   # tamanho da camada oculta nas redes feed forward dentro do transformer\n",
    "\n",
    "# Path para o arquivo de dados da b2w\n",
    "# B2W_DATAFILE = \"/home/wseidel/workspaces/usp/b2w-reviews01/B2W-Reviews01.csv\"\n",
    "B2W_DATAFILE = \"/home/wesley/workspaces/usp/data/b2w/B2W-Reviews01.csv\"\n",
    "# B2W_DATAFILE = \"/home/wseidel/workspaces/usp/b2w-reviews01/B2W-10k.csv\"\n",
    "\n",
    "\n",
    "# Path para o arquivo de dados de embeddings do NILC\n",
    "# NILC_W2V_DATAFILE = \"/home/wseidel/workspaces/usp/NILC/word2vec_200k.txt\"\n",
    "NILC_W2V_DATAFILE = \"/home/wesley/workspaces/usp/data/nilc/word2vec_200k.txt\"\n",
    "\n",
    "# Quantidade de epocas para o treino\n",
    "QNT_EPOCAS_A_TREINAR = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados a serem analisados\n",
    "b2wCorpus = pd.read_csv(B2W_DATAFILE, sep=';', usecols=[\"review_text\", \"overall_rating\"])\n",
    "\n",
    "# Carregar o Word2Vec do NILC\n",
    "# model_w2v = KeyedVectors.load_word2vec_format(NILC_W2V_DATAFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_text\n",
       "overall_rating             \n",
       "1                     27369\n",
       "2                      8389\n",
       "3                     16315\n",
       "4                     32345\n",
       "5                     47955"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus.groupby(['overall_rating']).count()\n",
    "# b2wCorpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(dataset, train_size=0.6, test_size=0.3, colname_stratify='overall_rating',random_seed=29):\n",
    "    val_size = 1 - round((train_size + test_size),1)\n",
    "    split_train_test_size = test_size + val_size\n",
    "\n",
    "    train, val = train_test_split(dataset, \n",
    "                                  test_size=split_train_test_size, \n",
    "                                  stratify=dataset[colname_stratify], \n",
    "                                  random_state=random_seed)\n",
    "\n",
    "    test, val = train_test_split(val, \n",
    "                                  test_size=val_size/split_train_test_size, \n",
    "                                  stratify=val[colname_stratify], \n",
    "                                  random_state=random_seed)\n",
    "    return train.reset_index(), test, val\n",
    "\n",
    "\n",
    "def sentence_to_nilc_index_token(text, stem=False):\n",
    "    # Traduzindo os tokens do B2W para o index do NILC\n",
    "#     tokens = text.lower().split() # Pegar um tokenizer decente...\n",
    "    tokens = tknzr.tokenize(text.lower())\n",
    "    tokens = [model_w2v.vocab[t].index if t in model_w2v.vocab else 19999 for t in tokens ]\n",
    "    return tokens\n",
    "\n",
    "def sort_by_size(df, col_to_sort):\n",
    "    df['sentence_length'] = df[col_to_sort].apply(lambda x: len(x))\n",
    "    df.sort_values(by=['sentence_length'], inplace=True, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def getXY(serieX, serieY, padding_maxlen=50):\n",
    "    x_train = keras.preprocessing.sequence.pad_sequences(train['review_text_clean'], maxlen=padding_maxlen, padding='post')\n",
    "    y_train = train['overall_rating']\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "class Vectorization:\n",
    "    def __init__(self, data_to_adapt):\n",
    "        self.vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=20000,\n",
    "            output_mode='int', # \"int\", \"binary\", \"count\" or \"tf-idf\",\n",
    "            output_sequence_length=50,  # Only valid in INT mode.\n",
    "        )\n",
    "        self.vectorize_layer.adapt( data_to_adapt )\n",
    "        self.modelVectorization = tf.keras.models.Sequential()\n",
    "        self.modelVectorization.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "        self.modelVectorization.add(self.vectorize_layer)\n",
    "    def predict(self, input_data ):\n",
    "        return self.modelVectorization.predict(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b0acc11fd268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Aplicando o sentence_to_nilc_index_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_to_work\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_text_clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_work\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_to_nilc_index_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# vectorization = Vectorization( b2wCorpus['review_text'].values )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b0acc11fd268>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Aplicando o sentence_to_nilc_index_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_to_work\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_text_clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_work\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_to_nilc_index_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# vectorization = Vectorization( b2wCorpus['review_text'].values )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a1ff9889c395>\u001b[0m in \u001b[0;36msentence_to_nilc_index_token\u001b[0;34m(text, stem)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     tokens = text.lower().split() # Pegar um tokenizer decente...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtknzr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m19999\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a1ff9889c395>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     tokens = text.lower().split() # Pegar um tokenizer decente...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtknzr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m19999\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "# ------ main ----\n",
    "df_to_work = b2wCorpus\n",
    "\n",
    "TAMMAX_SENTENCE=50\n",
    "\n",
    "values_to_retain=[1,2,3,4,5]\n",
    "df_to_work = df_to_work[df_to_work['overall_rating'].isin(values_to_retain)]\n",
    "# df_to_work\n",
    "df_to_work['overall_rating'] = df_to_work.overall_rating.apply(lambda x: x-1)\n",
    "\n",
    "\n",
    "# Aplicando o sentence_to_nilc_index_token\n",
    "df_to_work['review_text_clean'] = df_to_work.review_text.apply(lambda x: sentence_to_nilc_index_token(x))\n",
    "\n",
    "# vectorization = Vectorization( b2wCorpus['review_text'].values )\n",
    "# df_to_work['review_text_clean'] = df_to_work.review_text.apply(lambda x: vectorization.predict([[x]])[0])\n",
    "\n",
    "\n",
    "# train, test, val = train_test_val_split(df_to_work, train_size=0.75, test_size=0.15)\n",
    "train, test, val = train_test_val_split(df_to_work)\n",
    "\n",
    "sort_by_size(train, 'review_text_clean')\n",
    "\n",
    "\n",
    "x_train, y_train = getXY(train['review_text_clean'], train['overall_rating'], padding_maxlen=TAMMAX_SENTENCE)\n",
    "x_test,  y_test  = getXY(test['review_text_clean'], test['overall_rating'], padding_maxlen=TAMMAX_SENTENCE)\n",
    "x_val,   y_val   = getXY(val['review_text_clean'], val['overall_rating'], padding_maxlen=TAMMAX_SENTENCE)\n",
    "\n",
    "\n",
    "print(\"train..:\", len(train), round(len(train) / len(df_to_work),3) ) \n",
    "print(\"test...:\", len(test), round(len(test) / len(df_to_work),3) )\n",
    "print(\"val....:\", len(val), round(len(val) / len(df_to_work),3) )\n",
    "print(\"--\" * 20) \n",
    "print(\"x_train..:\", len(x_train[-1]), ) \n",
    "print(\"x_test...:\", len(x_test[-1]), ) \n",
    "print(\"x_val....:\", len(x_val[-1]), ) \n",
    "# train = train.reset_index(drop=True)\n",
    "# train = train.reset_index(inplace=True)\n",
    "# train = train.copy()\n",
    "\n",
    "# df_to_work.groupby\n",
    "df_to_work.groupby(['overall_rating']).count()\n",
    "# b2wCorpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [48, 1409, 12, 4, 54, 19, 65, 2, 494, 102, 12,...\n",
       "1    [38, 160, 1, 383, 67, 66, 143, 655, 5, 3128, 0...\n",
       "2    [2412, 20, 696, 3, 917, 292, 611, 1, 4054, 127...\n",
       "3    [39, 300, 504, 192, 5, 570, 12, 3344, 1040, 7,...\n",
       "4    [4, 19, 30, 18, 28, 29, 40, 268, 5, 129, 4, 53...\n",
       "5    [32, 6, 38, 209, 20, 147, 3128, 43, 284, 3, 38...\n",
       "6    [6, 600, 15, 12, 114, 6800, 374, 176, 56, 2671...\n",
       "7    [6, 32, 26, 49, 196, 3150, 11, 737, 12, 495, 0...\n",
       "8    [2, 507, 3, 2707, 3, 2, 2239, 10, 25, 466, 21,...\n",
       "9    [39, 6, 69, 30, 94, 3, 4, 40, 125, 14931, 21, ...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab = set()\n",
    "# def sentence_to_nilc_index_token(text, stem=False):\n",
    "#     # Traduzindo os tokens do B2W para o index do NILC\n",
    "# #     tokens = text.lower().split() # Pegar um tokenizer decente...\n",
    "#     tokens = tknzr.tokenize(text.lower())\n",
    "#     for t in tokens:\n",
    "#         vocab.add(t)\n",
    "#     return 1\n",
    "\n",
    "# df_to_work.review_text.apply(lambda x: sentence_to_nilc_index_token(x))\n",
    "# vectorization.predict([[\"acho oque isso é otimo\"]])[0]\n",
    "# df_to_work['review_text_clean'] = df_to_work.review_text.apply(lambda x: vectorization.predict([[x]])[0])\n",
    "\n",
    "df_to_work.review_text[0:10].apply(lambda x: vectorization.predict([[x]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['produto', 'comprei qualidade', 'exatamente']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab = set()\n",
    "# vocab.add(2)\n",
    "vocab\n",
    "'produto.comprei qualidade.exatamente'.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qnt dados..: 19\n",
      "lote size..: 3\n",
      "lote count..: 7\n",
      "Pegando lote 0 de 7:[0, 1, 2]\n",
      "Pegando lote 1 de 7:[3, 4, 5]\n",
      "Pegando lote 2 de 7:[6, 7, 8]\n",
      "Pegando lote 3 de 7:[9, 10, 11]\n",
      "Pegando lote 4 de 7:[12, 13, 14]\n",
      "Pegando lote 5 de 7:[15, 16, 17]\n",
      "Pegando lote 6 de 7:[18]\n"
     ]
    }
   ],
   "source": [
    "dados = list(range(19))\n",
    "lote_size = 3\n",
    "lote_count = int(np.ceil(len(dados)/ lote_size))\n",
    "print(\"qnt dados..:\", len(dados))\n",
    "print(\"lote size..:\", lote_size)\n",
    "print(\"lote count..:\", lote_count)\n",
    "for i in range(0,lote_count):\n",
    "    print(f\"Pegando lote {i} de {lote_count}:\", end=\"\")\n",
    "    print(dados[ i*lote_size : i*lote_size+lote_size ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 50)            10000000  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 10,029,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 10,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras import Sequential\n",
    "# from keras.utils import Sequence\n",
    "# from keras.layers import LSTM, Dense, Masking\n",
    "# import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "# model = tf.keras.Sequential([\n",
    "from tensorflow import keras\n",
    "\n",
    "def get_lstm_model(dropout_prob=0.0):\n",
    "    embedding_layer = model_w2v.get_keras_embedding()\n",
    "#     embedding_layer.trainable = True\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(TAMMAX_SENTENCE, )))\n",
    "    model.add(embedding_layer)\n",
    "    model.add(layers.LSTM(64))\n",
    "    model.add(layers.Dropout(dropout_prob))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "    model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_lstm_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'm1_lstm_drop0.0'\n",
    "# model = get_lstm_model(dropout_prob=0.5)\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "# mc = ModelCheckpoint('../model_data/' + name + 'best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "# history = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_val, y_val), callbacks=[es, mc])\n",
    "# save_history(history, name)\n",
    "# model.evaluate(x_test, y_test)\n",
    "# display_loss_plot(history, name)\n",
    "# display_acc_plot(history, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2444/2482 [============================>.] - ETA: 1s - loss: 1.1693 - accuracy: 0.5068"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-747131da179b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQNT_EPOCAS_TREINO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dados/home/wseidel/envs/usp-MAC5725c/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ver lista06\n",
    "\n",
    "# Ler aqui pro batch generator:\n",
    "#     https://datascience.stackexchange.com/questions/48796/how-to-feed-lstm-with-different-input-array-sizes\n",
    "\n",
    "# Seu código aqui\n",
    "\n",
    "QNT_EPOCAS_TREINO = 10\n",
    "\n",
    "\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=QNT_EPOCAS_TREINO, validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(x=x_test,y=y_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparações \n",
    "\n",
    "# Dropout 0.0\n",
    "\n",
    "### embedding_layer.trainable = True\n",
    "```\n",
    "Epoch 1/10\n",
    "2482/2482 [==============================] - 383s 154ms/step - loss: 1.0851 - accuracy: 0.5380 - val_loss: 0.9881 - val_accuracy: 0.5780\n",
    "Epoch 2/10\n",
    "2482/2482 [==============================] - 400s 161ms/step - loss: 0.9654 - accuracy: 0.5859 - val_loss: 0.9020 - val_accuracy: 0.6110\n",
    "Epoch 3/10\n",
    "2482/2482 [==============================] - 391s 157ms/step - loss: 0.9116 - accuracy: 0.6084 - val_loss: 0.8640 - val_accuracy: 0.6291\n",
    "Epoch 4/10\n",
    "2482/2482 [==============================] - 412s 166ms/step - loss: 0.8630 - accuracy: 0.6309 - val_loss: 0.7967 - val_accuracy: 0.6648\n",
    "Epoch 5/10\n",
    "2482/2482 [==============================] - 404s 163ms/step - loss: 0.8152 - accuracy: 0.6520 - val_loss: 0.7535 - val_accuracy: 0.6912\n",
    "Epoch 6/10\n",
    "2482/2482 [==============================] - 425s 171ms/step - loss: 0.7649 - accuracy: 0.6772 - val_loss: 0.6945 - val_accuracy: 0.7154\n",
    "Epoch 7/10\n",
    "2482/2482 [==============================] - 478s 193ms/step - loss: 0.7166 - accuracy: 0.6992 - val_loss: 0.6500 - val_accuracy: 0.7313\n",
    "Epoch 8/10\n",
    "2482/2482 [==============================] - 492s 198ms/step - loss: 0.6680 - accuracy: 0.7196 - val_loss: 0.6138 - val_accuracy: 0.7464\n",
    "Epoch 9/10\n",
    "2482/2482 [==============================] - 481s 194ms/step - loss: 0.6248 - accuracy: 0.7370 - val_loss: 0.5679 - val_accuracy: 0.7631\n",
    "Epoch 10/10\n",
    "2482/2482 [==============================] - 472s 190ms/step - loss: 0.5873 - accuracy: 0.7511 - val_loss: 0.5323 - val_accuracy: 0.7761\n",
    "2482/2482 [==============================] - 29s 12ms/step - loss: 0.5323 - accuracy: 0.7761\n",
    "Loss:  0.532257080078125\n",
    "Accuracy:  0.7761353850364685\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### embedding_layer.trainable = False\n",
    "```\n",
    "Epoch 1/10\n",
    "2482/2482 [==============================] - 90s 36ms/step - loss: 1.2016 - accuracy: 0.4954 - val_loss: 1.1219 - val_accuracy: 0.5238\n",
    "Epoch 2/10\n",
    "2482/2482 [==============================] - 88s 35ms/step - loss: 1.1006 - accuracy: 0.5322 - val_loss: 1.0658 - val_accuracy: 0.5467\n",
    "Epoch 3/10\n",
    "2482/2482 [==============================] - 89s 36ms/step - loss: 1.0550 - accuracy: 0.5500 - val_loss: 1.0191 - val_accuracy: 0.5655\n",
    "Epoch 4/10\n",
    "2482/2482 [==============================] - 92s 37ms/step - loss: 1.0298 - accuracy: 0.5603 - val_loss: 1.0086 - val_accuracy: 0.5682\n",
    "Epoch 5/10\n",
    "2482/2482 [==============================] - 94s 38ms/step - loss: 1.0102 - accuracy: 0.5693 - val_loss: 0.9865 - val_accuracy: 0.5761\n",
    "Epoch 6/10\n",
    "2482/2482 [==============================] - 91s 37ms/step - loss: 0.9939 - accuracy: 0.5742 - val_loss: 0.9819 - val_accuracy: 0.5804\n",
    "Epoch 7/10\n",
    "2482/2482 [==============================] - 88s 35ms/step - loss: 0.9813 - accuracy: 0.5799 - val_loss: 0.9750 - val_accuracy: 0.5857\n",
    "Epoch 8/10\n",
    "2482/2482 [==============================] - 87s 35ms/step - loss: 0.9705 - accuracy: 0.5850 - val_loss: 0.9909 - val_accuracy: 0.5775\n",
    "Epoch 9/10\n",
    "2482/2482 [==============================] - 84s 34ms/step - loss: 0.9597 - accuracy: 0.5883 - val_loss: 0.9482 - val_accuracy: 0.5949\n",
    "Epoch 10/10\n",
    "2482/2482 [==============================] - 85s 34ms/step - loss: 0.9503 - accuracy: 0.5919 - val_loss: 0.9388 - val_accuracy: 0.5954\n",
    "2482/2482 [==============================] - 26s 11ms/step - loss: 0.9388 - accuracy: 0.5954\n",
    "\n",
    "No teste:\n",
    "Loss:  0.9387642741203308\n",
    "Accuracy:  0.5953942537307739\n",
    "```\n",
    "\n",
    "\n",
    "###  embedding_layer.trainable = False e o UNK sendo -19999\n",
    "```\n",
    "Epoch 1/10\n",
    "2482/2482 [==============================] - 138s 56ms/step - loss: 1.2058 - accuracy: 0.4917 - val_loss: 1.1347 - val_accuracy: 0.5199\n",
    "Epoch 2/10\n",
    "2482/2482 [==============================] - 129s 52ms/step - loss: 1.1054 - accuracy: 0.5303 - val_loss: 1.0637 - val_accuracy: 0.5500\n",
    "Epoch 3/10\n",
    "2482/2482 [==============================] - 128s 52ms/step - loss: 1.0628 - accuracy: 0.5495 - val_loss: 1.0425 - val_accuracy: 0.5602\n",
    "Epoch 4/10\n",
    "2482/2482 [==============================] - 125s 51ms/step - loss: 1.0364 - accuracy: 0.5590 - val_loss: 1.0186 - val_accuracy: 0.5630\n",
    "Epoch 5/10\n",
    " 143/2482 [>.............................] - ETA: 1:31 - loss: 1.0195 - accuracy: 0.5660\n",
    " ```\n",
    "\n",
    "###  [embedding_layer.trainable = False] e o [UNK = pos -19999] (nltk tokenizer twitter)\n",
    "``` \n",
    "Epoch 1/10\n",
    "2482/2482 [==============================] - 187s 75ms/step - loss: 1.1684 - accuracy: 0.5067 - val_loss: 1.0854 - val_accuracy: 0.5410\n",
    "Epoch 2/10\n",
    "2482/2482 [==============================] - 172s 69ms/step - loss: 1.0489 - accuracy: 0.5517 - val_loss: 1.0070 - val_accuracy: 0.5755\n",
    "Epoch 3/10\n",
    "2482/2482 [==============================] - 169s 68ms/step - loss: 0.9994 - accuracy: 0.5731 - val_loss: 0.9720 - val_accuracy: 0.5846\n",
    "Epoch 4/10\n",
    "2482/2482 [==============================] - 129s 52ms/step - loss: 0.9737 - accuracy: 0.5837 - val_loss: 0.9497 - val_accuracy: 0.5915\n",
    "Epoch 5/10\n",
    "2482/2482 [==============================] - 87s 35ms/step - loss: 0.9521 - accuracy: 0.5920 - val_loss: 0.9395 - val_accuracy: 0.5960\n",
    "Epoch 6/10\n",
    "2482/2482 [==============================] - 86s 35ms/step - loss: 0.9380 - accuracy: 0.5963 - val_loss: 0.9266 - val_accuracy: 0.6064\n",
    "Epoch 7/10\n",
    "2482/2482 [==============================] - 119s 48ms/step - loss: 0.9238 - accuracy: 0.6011 - val_loss: 0.8999 - val_accuracy: 0.6130\n",
    "Epoch 8/10\n",
    "2482/2482 [==============================] - 132s 53ms/step - loss: 0.9126 - accuracy: 0.6051 - val_loss: 0.8931 - val_accuracy: 0.6152\n",
    "Epoch 9/10\n",
    "2482/2482 [==============================] - 119s 48ms/step - loss: 0.9021 - accuracy: 0.6116 - val_loss: 0.8847 - val_accuracy: 0.6161\n",
    "Epoch 10/10\n",
    "2482/2482 [==============================] - 125s 50ms/step - loss: 0.8907 - accuracy: 0.6145 - val_loss: 0.8713 - val_accuracy: 0.6226\n",
    "2482/2482 [==============================] - 30s 12ms/step - loss: 0.8713 - accuracy: 0.6226\n",
    "Loss:  0.8712893724441528\n",
    "Accuracy:  0.6226407885551453\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "y_pred[0]\n",
    "# y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
