{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "723yl-dYmrS2"
   },
   "source": [
    "<img src=\"https://github.com/alan-barzilay/NLPortugues/blob/master/imagens/logo_nlportugues.png?raw=true\"  style=\"height:65%\" align=\"right\">\n",
    "\n",
    "\n",
    "# Lista10 - BERT\n",
    "**Nome:**  Wesley Seidel Carvalho\n",
    "\n",
    "**Numero Usp:** 6544342\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "______________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elUy3yJQmrS9"
   },
   "source": [
    "\n",
    "O objetivo desta lista é fazer com que vocês se familiarizem com o BERT por meio da biblioteca HuggingFace. Novamente, as questões 1 2 e 3 podem ser copiadas de listas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkCzL_OHmrTB",
    "outputId": "6fe55b93-f67b-4a6d-d118-625c94044d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vr5lAyHfmrTc",
    "outputId": "0a9cd2e4-38b5-4aa1-bebb-1b358eece44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 11 03:04:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   76C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yntL_jNRmrTp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    TFBertForSequenceClassification,\n",
    "    TFTrainer,\n",
    "    TFTrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMWZdtOOmrT2"
   },
   "source": [
    "### Importando os dados como um dataframe\n",
    "\n",
    "Para esta lista nós utilizaremos o dataset **B2W-Reviews01** que consiste em avaliações de mais de 130k compras online no site Americanas.com e [esta disponivel no github](https://github.com/b2wdigital/b2w-reviews01) sob a licensa CC BY-NC-SA 4.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "B4pGXAmSmrT4",
    "outputId": "5cd25b0f-ef72-4d7c-d460-9dcefc1132f4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>site_category_lv1</th>\n",
       "      <th>site_category_lv2</th>\n",
       "      <th>review_title</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_birth_year</th>\n",
       "      <th>reviewer_gender</th>\n",
       "      <th>reviewer_state</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:11:28</td>\n",
       "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
       "      <td>132532965</td>\n",
       "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informática</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Bom</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1958</td>\n",
       "      <td>F</td>\n",
       "      <td>RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:13:48</td>\n",
       "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
       "      <td>22562178</td>\n",
       "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Copos, Taças e Canecas</td>\n",
       "      <td>Preço imbatível, ótima qualidade</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1996</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:26:02</td>\n",
       "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
       "      <td>113022329</td>\n",
       "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
       "      <td>philips walita</td>\n",
       "      <td>Eletroportáteis</td>\n",
       "      <td>Panela Elétrica</td>\n",
       "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1984</td>\n",
       "      <td>M</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:35:54</td>\n",
       "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
       "      <td>113851581</td>\n",
       "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
       "      <td>roma jensen</td>\n",
       "      <td>Brinquedos</td>\n",
       "      <td>Veículos de Brinquedo</td>\n",
       "      <td>presente mais que desejado</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1985</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:28</td>\n",
       "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
       "      <td>131788803</td>\n",
       "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
       "      <td>lg</td>\n",
       "      <td>TV e Home Theater</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sem duvidas, excelente</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1994</td>\n",
       "      <td>M</td>\n",
       "      <td>MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       submission_date  ... Unnamed: 18\n",
       "0  2018-01-01 00:11:28  ...         NaN\n",
       "1  2018-01-01 00:13:48  ...         NaN\n",
       "2  2018-01-01 00:26:02  ...         NaN\n",
       "3  2018-01-01 00:35:54  ...         NaN\n",
       "4  2018-01-01 01:00:28  ...         NaN\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus = pd.read_csv(\"https://raw.githubusercontent.com/abarbosa94/NLPortugues/master/Semana%2009/data/b2w-10k.csv\")\n",
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQdq2kVqmrUG",
    "outputId": "69507d23-e13d-4b84-e729-d09e0ee29464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Estou contente com a compra entrega rápida o ú...\n",
       "1       Por apenas R$1994.20,eu consegui comprar esse ...\n",
       "2       SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...\n",
       "3       MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...\n",
       "4       A entrega foi no prazo, as americanas estão de...\n",
       "                              ...                        \n",
       "9994    Celular muito rápido, com processador e armaze...\n",
       "9995    achei o produto muito frágil, o material veio ...\n",
       "9996    Uma porcaria pois ñ recebi ñ recomendo pra nin...\n",
       "9997    Maquina excelente,super pratica. recomendo.ent...\n",
       "9998    Agradeço pelo compromisso, obrigado. ,...........\n",
       "Name: review_text, Length: 9999, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"review_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq_DEzCJmrUZ"
   },
   "source": [
    "\n",
    "### Pré-processamento\n",
    "Seria util nos livrarmos das colunas que não são relevantes para o nosso problema e tambem verificar se não tem nada de esquisito nas colunas que vamos utilizar. \n",
    "Por exemplo, se fossemos utilizar a coluna \"reviewer_gender\" nós precisariamos nos livrar desses valores esquisitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsFaqFYXmrUe",
    "outputId": "5b52c94b-0385-40ba-d66a-216463771694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M                                                                         5033\n",
       "F                                                                         4624\n",
       "1970                                                                         1\n",
       "                                                                             1\n",
       "Ocorrência: Z-Devolução Em Andamento Ao Cd de São Paulo 22/12/17 16:12       1\n",
       "Name: reviewer_gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"reviewer_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q61JFx2zmrUz"
   },
   "source": [
    "## <font color='blue'>Questão 1 </font>\n",
    "\n",
    "a) Selecione apenas as colunas relevantes: \"review_text\" e \"recommend_to_a_friend\". \n",
    "\n",
    "b) Converta a coluna \"recommend_to_a_friend\" de uma coluna de `str` para uma coluna de `int`:\n",
    "\n",
    "- \"Yes\"-> 1\n",
    "- \"No\" -> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "KHCrVJjLmrU1",
    "outputId": "3c06304b-47a3-46c5-b41b-5beccac0906b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend_to_a_friend_new</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2548</td>\n",
       "      <td>2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7451</td>\n",
       "      <td>7451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           review_text  recommend_to_a_friend\n",
       "recommend_to_a_friend_new                                    \n",
       "0                                 2548                   2548\n",
       "1                                 7451                   7451"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "df = b2wCorpus[[\"review_text\", \"recommend_to_a_friend\"]]\n",
    "df = df.assign(recommend_to_a_friend_new=0)\n",
    "df['recommend_to_a_friend_new'] = df.recommend_to_a_friend.apply(lambda word : 1 if word == 'Yes' else 0)\n",
    "\n",
    "# df.head()\n",
    "df.groupby(by=\"recommend_to_a_friend_new\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yo1EtKImrVH"
   },
   "source": [
    "### Separando em teste e treino\n",
    "## <font color='blue'>Questão 2 </font>\n",
    "\n",
    "Agora com o dataset já pré-processado, separe o em 2 partes, um conjunto de teste e um conjunto de treino. Novamente você pode utilizar a função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn como na lista passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AYD_mLIXmrVJ"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['review_text'].values, df['recommend_to_a_friend_new'].values, test_size=0.20) # , random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkKN8m4mrVb"
   },
   "source": [
    "### Tokenizando\n",
    "\n",
    "Para aplicar o processo de _Tokenize_ dos nossos dados, diferente das listas anteriores, utilizaremos a classe [BertTokenizer](https://huggingface.co/transformers/master/model_doc/bert.html#berttokenizer) da biblioteca [transformers](https://github.com/huggingface/transformers) do HuggingFace.\n",
    "\n",
    "Para isso, veja o exemplo abaixo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ra_E9gMmrWb"
   },
   "source": [
    "Como é possível ver, o resultado gera um dicionário com 3 chaves, representando diferentes tensores:\n",
    "\n",
    "    - input_ids (os arrays de entrada convertidos para inteiro)\n",
    "    - token_type_ids (Indicação se pertence a sentença A ou B [0 é sentença A e 1 é sentença B])\n",
    "    - attention_mask (indicando quais tokens foram mascarados. Como todos os tokens **não** foram mascarados, o valor aqui sempre é 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3SYgHWgmrWk"
   },
   "source": [
    "## <font color='blue'>Questão 3 </font>\n",
    "\n",
    "Aplique o tokenizer nos dados de treino e teste, gerando duas variáveis **encoded_train** e **encoded_test**, considerando o max_length como o tamanho da sentença ideal. Plotamos um histograma do comprimento dos reviews para lhe auxiliar nessa decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Kk2klz9lmrWo",
    "outputId": "0920882c-b071-4daf-ae6c-317868322df4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(linha.split()) for linha in b2wCorpus[\"review_text\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Je6EI5y9P886"
   },
   "outputs": [],
   "source": [
    "REF_MODEL = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(REF_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYMgxlBcQCrb"
   },
   "outputs": [],
   "source": [
    "# text.values.tolist()\n",
    "# x_train.tolist()\n",
    "# [ [t] for t in x_train[0:10]]\n",
    "# x_train[0:10]\n",
    "# np.expand_dims(x_train[0:10], axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qOC9BO1ymrW2"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "SEQ_LEN=50\n",
    "\n",
    "encoded_train = tokenizer(\n",
    "    np.expand_dims(x_train, axis=1).tolist(),\n",
    "    text_pair=None,\n",
    "    is_split_into_words=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=SEQ_LEN,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "# encoded_text_labels = np.array([0,0,1])\n",
    "# encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MsPmBJvemrXC"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "encoded_test =  tokenizer(\n",
    "    np.expand_dims(x_test, axis=1).tolist(),\n",
    "    text_pair=None,\n",
    "    is_split_into_words=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=SEQ_LEN,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWWAeovrmrXO",
    "outputId": "378e4b9d-a6b2-428e-bad0-864b2ce34c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do treino: (7999, 50)\n",
      "Shape do teste.: (2000, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \"Shape do treino:\", encoded_train['input_ids'].shape)\n",
    "print( \"Shape do teste.:\", encoded_test['input_ids'].shape)\n",
    "encoded_test.keys()\n",
    "# print( \"Shape do teste.:\", encoded_test['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rTBlaNRmrXc"
   },
   "source": [
    "### Montando o modelo\n",
    "\n",
    "Para montar o modelo, iremos utilizar a classe TFBertForSequenceClassification, do HuggingFace\n",
    "\n",
    "Aqui tem um exemplo de código para vocês seguirem!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FusDr7AEmrYS"
   },
   "source": [
    "## Treinando e avaliando seu modelo\n",
    "\n",
    "###  <font color='blue'>Questão 4 </font>\n",
    "\n",
    "Defina e treine seu modelo.\n",
    "\n",
    "**Lembre-se de tambem adicionar os dados de validação do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GshFvxOL5Xh",
    "outputId": "34d5f6fc-77ee-4d97-97a1-23c898f337bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_sequence_classifica ((None, 2),)         108924674   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,924,674\n",
      "Trainable params: 108,924,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained(REF_MODEL, from_pt=True, num_labels=2)\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name='masked_token', dtype='int32')\n",
    "\n",
    "X = bert_model(input_ids, input_masks_ids)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bQ29HkA0MLb7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-06)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    "\n",
    "model.compile(optimizer, loss, metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5LwIjVOmrYX",
    "outputId": "62624d05-fd5a-4e0b-97ad-c34f79c10800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.3595 - acc: 0.8465 - val_loss: 0.2272 - val_acc: 0.9100\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.2023 - acc: 0.9277 - val_loss: 0.2069 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.1720 - acc: 0.9415 - val_loss: 0.2093 - val_acc: 0.9280\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.1493 - acc: 0.9524 - val_loss: 0.2082 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.1258 - acc: 0.9649 - val_loss: 0.2261 - val_acc: 0.9290\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "history = model.fit(\n",
    "    [encoded_train[\"input_ids\"], encoded_train[\"attention_mask\"]],\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=([encoded_test[\"input_ids\"], encoded_test[\"attention_mask\"]], y_test),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z46gCYLT5SCV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lista 10 - BERT Fine-tuning.ipynb - Wesley",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
