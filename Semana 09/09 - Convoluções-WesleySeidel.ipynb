{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/alan-barzilay/NLPortugues/blob/master/imagens/logo_nlportugues.png?raw=true\"  style=\"height:65%\" align=\"right\">\n",
    "\n",
    "\n",
    "# Lista 9 -  Convoluções\n",
    "**Nome:** Wesley Seidel Carvalho\n",
    "\n",
    "**Numero Usp:** 6544342\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "______________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo desta lista é fazer com que vocês se familiarizem com redes convolucionais, vocês ja tiveram um contato breve com essa arquitetura algumas listas atrás mas dessa vez vocês cuidarão sozinhos da implementação e deverão tomar medidas para evitar overfitting. Novamente, as questões 1 2 e 3 podem ser copiadas de listas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os dados como um dataframe\n",
    "\n",
    "Para esta lista nós utilizaremos o dataset **B2W-Reviews01** que consiste em avaliações de mais de 130k compras online no site Americanas.com e [esta disponivel no github](https://github.com/b2wdigital/b2w-reviews01) sob a licensa CC BY-NC-SA 4.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wseidel/virtualenvs/mac5725-NLP/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# b2wCorpus = pd.read_csv(\"data/b2w-10k.csv\")\n",
    "B2W_DATAFILE = \"/home/wseidel/workspaces/usp/b2w-reviews01/B2W-Reviews01.csv\"\n",
    "# b2wCorpus = pd.read_csv(\"/home/wseidel/workspaces/usp/b2w-reviews01/B2W-Reviews01.csv\")\n",
    "b2wCorpus = pd.read_csv(B2W_DATAFILE, sep=';', usecols=[\"review_text\", \"recommend_to_a_friend\"])\n",
    "# b2wCorpus = pd.read_csv(B2W_DATAFILE, sep=';')\n",
    "\n",
    "\n",
    "# b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Estou contente com a compra entrega rápida o ú...\n",
       "1         Por apenas R$1994.20,eu consegui comprar esse ...\n",
       "2         SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...\n",
       "3         MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...\n",
       "4         A entrega foi no prazo, as americanas estão de...\n",
       "                                ...                        \n",
       "132368    Vale muito, estou usando no controle do Xbox e...\n",
       "132369    Prático e barato, super indico o produto para ...\n",
       "132370    Chegou antes do prazo previsto e corresponde a...\n",
       "132371    Material fraco, poderia ser melhor. Ficou deve...\n",
       "132372    Comprei esse produto, quando chegou estava com...\n",
       "Name: review_text, Length: 132373, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"review_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pré-processamento\n",
    "Seria util nos livrarmos das colunas que não são relevantes para o nosso problema e tambem verificar se não tem nada de esquisito nas colunas que vamos utilizar. \n",
    "Por exemplo, se fossemos utilizar a coluna \"reviewer_gender\" nós precisariamos nos livrar desses valores esquisitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    66166\n",
       "F    62071\n",
       "Name: reviewer_gender, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"reviewer_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 1 </font>\n",
    "\n",
    "a) Selecione apenas as colunas relevantes: \"review_text\" e \"recommend_to_a_friend\". \n",
    "\n",
    "b) Converta a coluna \"recommend_to_a_friend\" de uma coluna de `str` para uma coluna de `int`:\n",
    "\n",
    "- \"Yes\"-> 1\n",
    "- \"No\" -> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    96368\n",
       "0    36005\n",
       "Name: recommend_to_a_friend_new, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "df = b2wCorpus\n",
    "\n",
    "df = df.assign(recommend_to_a_friend_new=0)\n",
    "df['recommend_to_a_friend_new'] = df.recommend_to_a_friend.apply(lambda word : 1 if word == 'Yes' else 0)\n",
    "# df = df.dropna()\n",
    "df[\"recommend_to_a_friend_new\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando em teste e treino\n",
    "## <font color='blue'>Questão 2 </font>\n",
    "\n",
    "Agora com o dataset já pré-processado, separe o em 2 partes, um conjunto de teste e um conjunto de treino. Novamente você pode utilizar a função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn como na lista passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['review_text'].values, df['recommend_to_a_friend_new'].values, test_size=0.20, random_state=17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizando\n",
    "\n",
    "Para alimentarmos os reviews a camada de embedding nós precisamos quebrar cada review em uma serie de tokens. Existem diversas maneiras de se realizar isso e poderiamos até mesmo usar outras bibliotecas como o spaCy. \n",
    "\n",
    "Por exemplo, o objeto [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) oferece um método `tokenize` para quebrar as palavras em tokens individuais ao mesmo tempo que filtra caracteres indesejados (por default os caracteres filtrados são: !\"#$\\%&()*+,-./:;<=>?@[\\\\]^_\\`{|}~\\t\\n).\n",
    "\n",
    "\n",
    "Para essa lista utilizaremos a camada [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) para automaticamente passar os reviews para caixa-baixa, extrair caracteres especiais e tokenizar as palavras de maneira a serem passadas para a camada de embedding. Ao tornarmos a etapa de tokenização uma camada de rede neural nós podemos incluir esse processamento dos reviews no proprio modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 3 </font>\n",
    "Utilizando a camada `TextVectorization` tokenize os inputs.\n",
    "Declare a camada e então chame a função `adapt()` para adequar o seu vocabulário aos reviews.\n",
    "\n",
    "Não se esqueça de se certificar que todas os reviews tenham o mesmo comprimento, seja por meio do uso de padding, truncamento ou uma mistura dos dois. Plotamos um histograma do comprimento dos reviews para lhe auxiliar nessa decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUlElEQVR4nO3dfYxd9X3n8fdn7UAIaTAPFqI2WjuKlcpB3YZYxFGqKApdMCSK+YNERtXiZr2xdkN2k+5KqdlKi5oEKexWpUFK6KLgxkRZDEvTxSJQ1wWqalfiYQgEMIQwBRJsAZ5gHnYb5cHpd/+4Pye3w/xsPNczd4D3S7qac77nd875Xt/LfOY83EuqCkmSZvLPxt2AJGnhMiQkSV2GhCSpy5CQJHUZEpKkrsXjbuBoO+WUU2rFihXjbkOSXlPuu+++H1XV0un1111IrFixgomJiXG3IUmvKUl+MFPd002SpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqSu190nrkexYsu3x7bvp7704bHtW5J6PJKQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1HTYkkmxNsi/Jw0O1/5bke0keTPKXSZYMLbs0yWSSx5KcO1Rf12qTSbYM1VcmubvVb0hyTKsf2+Yn2/IVR+tJS5JenVdzJPF1YN202i7gjKr6TeD7wKUASVYDG4B3tXW+mmRRkkXAV4DzgNXARW0swBXAlVX1DuAFYFOrbwJeaPUr2zhJ0jw6bEhU1d8B+6fV/rqqDrTZu4DlbXo9sL2qflpVTwKTwFntMVlVT1TVz4DtwPokAT4E3NTW3wZcMLStbW36JuDsNl6SNE+OxjWJfw3c1qaXAU8PLdvTar36ycCLQ4FzsP5PttWWv9TGv0KSzUkmkkxMTU2N/IQkSQMjhUSSPwQOAN88Ou3MTlVdU1VrqmrN0qVLx9mKJL2uzPqrwpP8HvAR4OyqqlbeC5w+NGx5q9GpPw8sSbK4HS0Mjz+4rT1JFgMntPGSpHkyqyOJJOuAzwEfraofDy3aAWxodyatBFYB9wD3AqvanUzHMLi4vaOFy53AhW39jcDNQ9va2KYvBO4YCiNJ0jw47JFEkuuBDwKnJNkDXMbgbqZjgV3tWvJdVfVvq2p3khuBRxichrqkqn7RtvNpYCewCNhaVbvbLv4A2J7ki8D9wLWtfi3wjSSTDC6cbzgKz1eSdAQOGxJVddEM5WtnqB0cfzlw+Qz1W4FbZ6g/weDup+n1nwAfO1x/kqS54yeuJUldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLXYUMiydYk+5I8PFQ7KcmuJI+3nye2epJclWQyyYNJzhxaZ2Mb/3iSjUP19yR5qK1zVZIcah+SpPnzao4kvg6sm1bbAtxeVauA29s8wHnAqvbYDFwNg1/4wGXAe4GzgMuGfulfDXxyaL11h9mHJGmeHDYkqurvgP3TyuuBbW16G3DBUP26GrgLWJLkNOBcYFdV7a+qF4BdwLq27G1VdVdVFXDdtG3NtA9J0jyZ7TWJU6vqmTb9LHBqm14GPD00bk+rHaq+Z4b6ofbxCkk2J5lIMjE1NTWLpyNJmsnIF67bEUAdhV5mvY+quqaq1lTVmqVLl85lK5L0hjLbkHiunSqi/dzX6nuB04fGLW+1Q9WXz1A/1D4kSfNktiGxAzh4h9JG4Oah+sXtLqe1wEvtlNFO4JwkJ7YL1ucAO9uyl5OsbXc1XTxtWzPtQ5I0TxYfbkCS64EPAqck2cPgLqUvATcm2QT8APh4G34rcD4wCfwY+ARAVe1P8gXg3jbu81V18GL4pxjcQXUccFt7cIh9SJLmyWFDoqou6iw6e4axBVzS2c5WYOsM9QngjBnqz8+0D0nS/PET15KkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHWNFBJJfj/J7iQPJ7k+yZuTrExyd5LJJDckOaaNPbbNT7blK4a2c2mrP5bk3KH6ulabTLJllF4lSUdu1iGRZBnwH4A1VXUGsAjYAFwBXFlV7wBeADa1VTYBL7T6lW0cSVa39d4FrAO+mmRRkkXAV4DzgNXARW2sJGmejHq6aTFwXJLFwFuAZ4APATe15duAC9r0+jZPW352krT69qr6aVU9CUwCZ7XHZFU9UVU/A7a3sZKkeTLrkKiqvcAfAz9kEA4vAfcBL1bVgTZsD7CsTS8Dnm7rHmjjTx6uT1unV3+FJJuTTCSZmJqamu1TkiRNM8rpphMZ/GW/Evh14HgGp4vmXVVdU1VrqmrN0qVLx9GCJL0ujXK66XeAJ6tqqqp+DnwLeD+wpJ1+AlgO7G3Te4HTAdryE4Dnh+vT1unVJUnzZJSQ+CGwNslb2rWFs4FHgDuBC9uYjcDNbXpHm6ctv6OqqtU3tLufVgKrgHuAe4FV7W6pYxhc3N4xQr+SpCO0+PBDZlZVdye5CfgOcAC4H7gG+DawPckXW+3atsq1wDeSTAL7GfzSp6p2J7mRQcAcAC6pql8AJPk0sJPBnVNbq2r3bPuVJB25WYcEQFVdBlw2rfwEgzuTpo/9CfCxznYuBy6foX4rcOsoPUqSZs9PXEuSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkrpFCIsmSJDcl+V6SR5O8L8lJSXYlebz9PLGNTZKrkkwmeTDJmUPb2djGP55k41D9PUkeautclSSj9CtJOjKjHkl8GfirqvoN4F8AjwJbgNurahVwe5sHOA9Y1R6bgasBkpwEXAa8FzgLuOxgsLQxnxxab92I/UqSjsCsQyLJCcAHgGsBqupnVfUisB7Y1oZtAy5o0+uB62rgLmBJktOAc4FdVbW/ql4AdgHr2rK3VdVdVVXAdUPbkiTNg1GOJFYCU8CfJ7k/ydeSHA+cWlXPtDHPAqe26WXA00Pr72m1Q9X3zFB/hSSbk0wkmZiamhrhKUmSho0SEouBM4Grq+rdwD/wq1NLALQjgBphH69KVV1TVWuqas3SpUvneneS9IYxSkjsAfZU1d1t/iYGofFcO1VE+7mvLd8LnD60/vJWO1R9+Qx1SdI8mXVIVNWzwNNJ3tlKZwOPADuAg3cobQRubtM7gIvbXU5rgZfaaamdwDlJTmwXrM8BdrZlLydZ2+5qunhoW5KkebB4xPX/PfDNJMcATwCfYBA8NybZBPwA+HgbeytwPjAJ/LiNpar2J/kCcG8b9/mq2t+mPwV8HTgOuK09JEnzZKSQqKoHgDUzLDp7hrEFXNLZzlZg6wz1CeCMUXqUJM2en7iWJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV0jh0SSRUnuT3JLm1+Z5O4kk0luSHJMqx/b5ifb8hVD27i01R9Lcu5QfV2rTSbZMmqvkqQjczSOJD4DPDo0fwVwZVW9A3gB2NTqm4AXWv3KNo4kq4ENwLuAdcBXW/AsAr4CnAesBi5qYyVJ82SkkEiyHPgw8LU2H+BDwE1tyDbggja9vs3Tlp/dxq8HtlfVT6vqSWASOKs9Jqvqiar6GbC9jZUkzZNRjyT+FPgc8I9t/mTgxao60Ob3AMva9DLgaYC2/KU2/pf1aev06q+QZHOSiSQTU1NTIz4lSdJBsw6JJB8B9lXVfUexn1mpqmuqak1VrVm6dOm425Gk143FI6z7fuCjSc4H3gy8DfgysCTJ4na0sBzY28bvBU4H9iRZDJwAPD9UP2h4nV5dkjQPZn0kUVWXVtXyqlrB4MLzHVX1u8CdwIVt2Ebg5ja9o83Tlt9RVdXqG9rdTyuBVcA9wL3Aqna31DFtHztm268k6ciNciTR8wfA9iRfBO4Hrm31a4FvJJkE9jP4pU9V7U5yI/AIcAC4pKp+AZDk08BOYBGwtap2z0G/kqSOoxISVfW3wN+26ScY3Jk0fcxPgI911r8cuHyG+q3ArUejR0nSkfMT15KkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpa9YhkeT0JHcmeSTJ7iSfafWTkuxK8nj7eWKrJ8lVSSaTPJjkzKFtbWzjH0+ycaj+niQPtXWuSpJRnqwk6ciMciRxAPhPVbUaWAtckmQ1sAW4vapWAbe3eYDzgFXtsRm4GgahAlwGvBc4C7jsYLC0MZ8cWm/dCP1Kko7QrEOiqp6pqu+06f8LPAosA9YD29qwbcAFbXo9cF0N3AUsSXIacC6wq6r2V9ULwC5gXVv2tqq6q6oKuG5oW5KkeXBUrkkkWQG8G7gbOLWqnmmLngVObdPLgKeHVtvTaoeq75mhLkmaJyOHRJK3An8BfLaqXh5e1o4AatR9vIoeNieZSDIxNTU117uTpDeMkUIiyZsYBMQ3q+pbrfxcO1VE+7mv1fcCpw+tvrzVDlVfPkP9FarqmqpaU1Vrli5dOspTkiQNGeXupgDXAo9W1Z8MLdoBHLxDaSNw81D94naX01rgpXZaaidwTpIT2wXrc4CdbdnLSda2fV08tC1J0jxYPMK67wf+FfBQkgda7T8DXwJuTLIJ+AHw8bbsVuB8YBL4MfAJgKran+QLwL1t3Oeran+b/hTwdeA44Lb2kCTNk1mHRFX9b6D3uYWzZxhfwCWdbW0Fts5QnwDOmG2PkqTR+IlrSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUtHncDGlix5dtj2e9TX/rwWPYr6bXBIwlJUpchIUnqWvAhkWRdkseSTCbZMu5+JOmNZEGHRJJFwFeA84DVwEVJVo+3K0l641joF67PAiar6gmAJNuB9cAjY+3qdcQL5pIOZaGHxDLg6aH5PcB7pw9KshnY3Gb/X5LHZrm/U4AfzXLdufS66ytXHOVOXul19282xxZqX7Bwe3u99fXPZyou9JB4VarqGuCaUbeTZKKq1hyFlo4q+zpyC7U3+zpyC7W3N0pfC/qaBLAXOH1ofnmrSZLmwUIPiXuBVUlWJjkG2ADsGHNPkvSGsaBPN1XVgSSfBnYCi4CtVbV7Dnc58imrOWJfR26h9mZfR26h9vaG6CtVdTS3J0l6HVnop5skSWNkSEiSugwJxv/VH0m2JtmX5OGh2klJdiV5vP08sdWT5KrW64NJzpzDvk5PcmeSR5LsTvKZhdBbkjcnuSfJd1tff9TqK5Pc3fZ/Q7vZgSTHtvnJtnzFXPQ11N+iJPcnuWWB9fVUkoeSPJBkotUWwvtsSZKbknwvyaNJ3jfuvpK8s/07HXy8nOSz4+5rqL/fb+/9h5Nc3/6bmJv3WVW9oR8MLoj/PfB24Bjgu8Dqee7hA8CZwMNDtf8KbGnTW4Ar2vT5wG1AgLXA3XPY12nAmW3614DvM/h6lLH21rb/1jb9JuDutr8bgQ2t/mfAv2vTnwL+rE1vAG6Y49fzPwL/A7ilzS+Uvp4CTplWWwjvs23Av2nTxwBLFkJfQ/0tAp5l8GGzsffF4EPGTwLHDb2/fm+u3mdz+o/7WngA7wN2Ds1fClw6hj5W8E9D4jHgtDZ9GvBYm/7vwEUzjZuHHm8G/uVC6g14C/AdBp/E/xGwePrryuDuuPe16cVtXOaon+XA7cCHgFvaL42x99X28RSvDImxvpbACe0XXhZSX9N6OQf4PwulL371TRQntffNLcC5c/U+83TTzF/9sWxMvQw7taqeadPPAqe26bH02w5R383gr/ax99ZO6TwA7AN2MTgafLGqDsyw71/21Za/BJw8F30Bfwp8DvjHNn/yAukLoIC/TnJfBl9lA+N/LVcCU8Cft1N0X0ty/ALoa9gG4Po2Pfa+qmov8MfAD4FnGLxv7mOO3meGxGtADf4EGNu9ykneCvwF8Nmqenl42bh6q6pfVNVvMfjL/SzgN+a7h+mSfATYV1X3jbuXjt+uqjMZfKvyJUk+MLxwTK/lYganWq+uqncD/8DgNM64+wKgndf/KPA/py8bV1/tOsh6BgH768DxwLq52p8hsXC/+uO5JKcBtJ/7Wn1e+03yJgYB8c2q+tZC6g2gql4E7mRweL0kycEPiA7v+5d9teUnAM/PQTvvBz6a5ClgO4NTTl9eAH0Bv/wLlKraB/wlg3Ad92u5B9hTVXe3+ZsYhMa4+zroPOA7VfVcm18Iff0O8GRVTVXVz4FvMXjvzcn7zJBYuF/9sQPY2KY3MrgecLB+cbubYi3w0tDh71GVJMC1wKNV9ScLpbckS5MsadPHMbhO8iiDsLiw09fBfi8E7mh/BR5VVXVpVS2vqhUM3kd3VNXvjrsvgCTHJ/m1g9MMzrM/zJhfy6p6Fng6yTtb6WwG/yuAsb//m4v41ammg/sfd18/BNYmeUv7b/Tgv9ncvM/m8oLPa+XB4M6E7zM4r/2HY9j/9QzOLf6cwV9WmxicM7wdeBz4G+CkNjYM/kdMfw88BKyZw75+m8Hh9IPAA+1x/rh7A34TuL/19TDwX1r97cA9wCSD0wPHtvqb2/xkW/72eXhNP8iv7m4ae1+th++2x+6D7/Nxv5ZtX78FTLTX838BJy6Qvo5n8Bf3CUO1sffV9vdHwPfa+/8bwLFz9T7zazkkSV2ebpIkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV3/HwjQ0hF7fwKIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(linha.split()) for linha in b2wCorpus[\"review_text\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
       "array([[3129,    1,   43, 2701,    8,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "\n",
    "VOCAB_SIZE = 20000\n",
    "EMBED_DIM = 64\n",
    "TAMMAX_SENTENCE = 50\n",
    "\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize='lower_and_strip_punctuation', \n",
    "    output_mode='int', \n",
    "    output_sequence_length=TAMMAX_SENTENCE,\n",
    "    name=\"TextVec_%d\" % VOCAB_SIZE\n",
    ")\n",
    "vectorize_layer.adapt(x_train)\n",
    "\n",
    "vectorize_layer([[\"Ola enfermeira gostei viu não\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o modelo\n",
    "\n",
    "Agora vamos juntar a camada do tokenizador a nossa camada [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) e definir o resto de nosso modelo.\n",
    "\n",
    "##  <font color='blue'>Questão 4 </font>\n",
    "\n",
    "Defina seu modelo.\n",
    "\n",
    "Como analise de sentimentos pode ser visto como um problema de classificação, é interessante também registrar algumas métricas como acurácia `metrics=[\"acc\"]` .\n",
    "\n",
    "Seu modelo deve começar com a seguinte estrutura:\n",
    " - Camada de Input\n",
    " - Camada de Tokenização\n",
    " - Camada de Embedding\n",
    " \n",
    "Já definimos as camadas seguintes da rede por você.\n",
    " \n",
    "Atenção a dimensão do input da camada de embedding, lembre se que < OOV > e < PAD > possuem seus próprios tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "TextVec_20000 (TextVectoriza (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "Emb_Zerado (Embedding)       (None, 50, 64)            1280128   \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 50, 16)            25616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 25, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 25, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 25, 32)            544       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 25, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 25, 1)             33        \n",
      "=================================================================\n",
      "Total params: 1,306,321\n",
      "Trainable params: 1,306,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "\n",
    "input_layer = layers.Input(shape=(1,), dtype=tf.string, name=\"Input_shape1\")\n",
    "embedding_layer = layers.Embedding(VOCAB_SIZE+2, output_dim=EMBED_DIM, input_length=TAMMAX_SENTENCE, name=\"Emb_Zerado\")\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(input_layer)\n",
    "model.add(vectorize_layer)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(layers.Conv1D(filters=16, kernel_size=25, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile( \"adam\",\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando seu modelo\n",
    "\n",
    "##  <font color='blue'>Questão 5 </font>\n",
    "\n",
    "Com seu modelo definido, treine e avalie sua performance no conjunto de testes, utilize camadas [Conv1D](https://keras.io/api/layers/convolution_layers/convolution1d/) na sua rede.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "828/828 [==============================] - 54s 66ms/step - loss: 0.4183 - accuracy: 0.8278\n",
      "Epoch 2/30\n",
      "828/828 [==============================] - 56s 68ms/step - loss: 0.3741 - accuracy: 0.8497\n",
      "Epoch 3/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.3598 - accuracy: 0.8560\n",
      "Epoch 4/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.3477 - accuracy: 0.8612\n",
      "Epoch 5/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.3358 - accuracy: 0.8665\n",
      "Epoch 6/30\n",
      "828/828 [==============================] - 62s 75ms/step - loss: 0.3238 - accuracy: 0.8720\n",
      "Epoch 7/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.3127 - accuracy: 0.8769\n",
      "Epoch 8/30\n",
      "828/828 [==============================] - 59s 71ms/step - loss: 0.3021 - accuracy: 0.8816\n",
      "Epoch 9/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.2935 - accuracy: 0.8854\n",
      "Epoch 10/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.2859 - accuracy: 0.8885\n",
      "Epoch 11/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.2795 - accuracy: 0.8912\n",
      "Epoch 12/30\n",
      "828/828 [==============================] - 58s 70ms/step - loss: 0.2741 - accuracy: 0.8933\n",
      "Epoch 13/30\n",
      "828/828 [==============================] - 58s 71ms/step - loss: 0.2690 - accuracy: 0.8953\n",
      "Epoch 14/30\n",
      "828/828 [==============================] - 61s 74ms/step - loss: 0.2650 - accuracy: 0.8970\n",
      "Epoch 15/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2616 - accuracy: 0.8982\n",
      "Epoch 16/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2584 - accuracy: 0.8995\n",
      "Epoch 17/30\n",
      "828/828 [==============================] - 55s 66ms/step - loss: 0.2560 - accuracy: 0.9004\n",
      "Epoch 18/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2531 - accuracy: 0.9015\n",
      "Epoch 19/30\n",
      "828/828 [==============================] - 55s 66ms/step - loss: 0.2507 - accuracy: 0.9025\n",
      "Epoch 20/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2488 - accuracy: 0.9031\n",
      "Epoch 21/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2473 - accuracy: 0.9038\n",
      "Epoch 22/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2459 - accuracy: 0.9044\n",
      "Epoch 23/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2443 - accuracy: 0.9049\n",
      "Epoch 24/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2430 - accuracy: 0.9054\n",
      "Epoch 25/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2414 - accuracy: 0.9061\n",
      "Epoch 26/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2407 - accuracy: 0.9063\n",
      "Epoch 27/30\n",
      "828/828 [==============================] - 56s 67ms/step - loss: 0.2393 - accuracy: 0.9069\n",
      "Epoch 28/30\n",
      "828/828 [==============================] - 56s 67ms/step - loss: 0.2385 - accuracy: 0.9072\n",
      "Epoch 29/30\n",
      "828/828 [==============================] - 55s 67ms/step - loss: 0.2373 - accuracy: 0.9076\n",
      "Epoch 30/30\n",
      "828/828 [==============================] - 56s 67ms/step - loss: 0.2370 - accuracy: 0.9077\n",
      "828/828 [==============================] - 3s 4ms/step - loss: 0.7153 - accuracy: 0.8311\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "\n",
    "QNT_EPOCAS_A_TREINAR = 30\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=QNT_EPOCAS_A_TREINAR)\n",
    "\n",
    "loss, accuracy = model.evaluate(x=x_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
